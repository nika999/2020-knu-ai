{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsXRPWN2BGOI"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FT51fCRBBGOQ"
   },
   "source": [
    "torch==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2gW25dyBGOU"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2814,
     "status": "ok",
     "timestamp": 1580424241727,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "mKkTU2XNLx49",
    "outputId": "b9650f09-2e57-46a0-c5b1-8577f328eb8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKY7yNrWBGOi"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1545,
     "status": "ok",
     "timestamp": 1580424273166,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "KEGjXaG4BGOr",
    "outputId": "2a294433-8dc3-48f1-9096-94cd19b4c2ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"d'aww\", 'match', 'background', 'colour', \"'m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', \"'m\", 'really', 'trying', 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'ca', \"n't\", 'make', 'real', 'suggestio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                             cleaned  \n",
       "0  ['explanation', 'edits', 'made', 'username', '...  \n",
       "1  [\"d'aww\", 'match', 'background', 'colour', \"'m...  \n",
       "2  ['hey', 'man', \"'m\", 'really', 'trying', 'edit...  \n",
       "3  ['``', 'ca', \"n't\", 'make', 'real', 'suggestio...  \n",
       "4  ['sir', 'hero', 'chance', 'remember', 'page', ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eTIPZlQmBGO4"
   },
   "source": [
    "In this notebook you will learn pytorch basics, this framework will help you to build simple neural networks during this task.   \n",
    "The first neural network we will try to learn is Feed Forward Neural Network which contain one Fully Connected Layer.  \n",
    "It can have 1 or more fully connected layers, also it could be called as MLP - multilayer perceptron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5ywM13rBGO7"
   },
   "source": [
    "Read about PyTorch here:  \n",
    "https://en.wikipedia.org/wiki/PyTorch\n",
    "\n",
    "And here:\n",
    "\n",
    "https://neurohive.io/ru/tutorial/glubokoe-obuchenie-s-pytorch/\n",
    "\n",
    "While reading these articles probably you will meet some unknown terms: \n",
    "backpropagation algorithm, gradient descent, activation function, loss function, etc.  \n",
    "Please, try to look for an information about why do you need all of these stuff. \n",
    "\n",
    "Answer this questions about Neural Nets: \n",
    "\n",
    "1. In previous tasks we created some features manually, tried to weight our features, tried to select special words for vectorization, how deep learning solves this problem? \n",
    "\n",
    "2. Why do we work with tensors in PyTorch?\n",
    "\n",
    "3. Please, find and read information - why do we need an activation functions in our models? Please, refer to the XOR problem with MLP without activation function, find information about it and answer the previous question. \n",
    "\n",
    "4. Please, answer the following question - what gradient is? Why do we need gradient descent algorithm? Which problem it solves? \n",
    "\n",
    "5. What is backpropagation algorithm? \n",
    "\n",
    "6. What is loss function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDoUrh2P5TrR"
   },
   "source": [
    "1.  Взять тот же Word2Vec, там есть реализация простой нейронной сети. Именно и она есть способом решения поставленной в вопросе проблемы. Дело в гибкости и настраиваемости параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6lawQyE4iun"
   },
   "source": [
    "2. По сути, тензоры библиотеки pytorch - те же многомерные массивы библиотеки numpy, обладающие аналогичными возможностями. Используються для вычислений. Если ещё глянуть документацию и поверить в написанное (но лучше проверить, что я и сделал), то вычисления на тензорах могут проводиться как на центральном процессоре, так и на графическом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ml9Nz4OqFCuo"
   },
   "source": [
    "3.  Активационный процесс заключается в том, когда при необходимом количестве входных данных нейрон передаёт значение далее по сети. Преобразовазованием этого значения занимается функция активации нейрона. Примеры активационных функций - сигмоидная функция (tanh, логистическая, ...), Хэвисайда и т.д.\n",
    "<br>\n",
    "Активационные функции необходимы для гибкости нейронной сети. Ними же решалась задача о линейной несепарабельности данных проблемы XOr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NACw-VV6FPD"
   },
   "source": [
    "4. Пусть $\\Omega \\subset \\mathbb{R}^d \\> (d \\in \\mathbb{N})$ - область в $\\mathbb{R}^d$. Тогда функция $\\phi: \\Omega \\rightarrow \\mathbb{R}$ - скалярное поле.\n",
    "<br>\n",
    "Градиентом $\\phi$ является следующее выражение:\n",
    "$\\nabla \\phi = (\\frac{\\partial \\phi}{\\partial t_1}, \\frac{\\partial \\phi}{\\partial t_2}, \\ldots, \\frac{\\partial \\phi}{\\partial t_d})$,<br>\n",
    "где $\\frac{\\partial \\phi}{\\partial t_j}$ - частная производная $\\phi$ за переменной $t_j$. Градиент отождествляют с направлением в $\\Omega$, в котором $\\phi$ возрастает быстрее всего.\n",
    "<br>\n",
    "Градиентный спуск - метод нахождения локального экстремума некоторой функции с применением её (отрицательного) градиента. В машинном обучении,если рассматривать нейронные сети, то указанный метод используется в обучении модели в качестве принципа обратного распространения ошибки (backpropagation method). Там же и берётся градиент от функции ошибок (она же определяет качество работу нейронной сети в период циклического обучения).\n",
    "<br>\n",
    "Градиентный спуск используется для решения задачи минимизации среднего значения ошибки на выходе нейронной сети, обновляя весовые параметры модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSmctPpCE3YZ"
   },
   "source": [
    "5. Принцип обратного распространения ошибки - способ вычисления градиента функции, который используется при обновлении параметров многослойного персептрона. Цель - минимизация ошибки и получение желаемого результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qtrb3bezBSV8"
   },
   "source": [
    "6. Функция потерь - чувствительная к выбросам функция несогласия наблюдаемых данных и тех, что были предсказаны так званой подогнанной функцией модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKmlTe8aBGP4"
   },
   "source": [
    "Read the following article:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Feedforward_neural_network\n",
    "\n",
    "What is FFNN? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCbY8qCEB0ra"
   },
   "source": [
    "Нейронная сеть с прямой связью - тип сети, где входные данные обрабатывается из одного конца потока в другой, при этом поток состоит из последовательно соединенных нейронов, которые передают необходимые сигналы.\n",
    "<br>\n",
    "Для такого типа сетей циклы или петли обратной связи не характерны.\n",
    "<br>\n",
    "Простые примеры сетей такого плана: персептроны однослойные и многослойные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbbPBeoHBGQA"
   },
   "source": [
    "## PyTorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDkbQ7i3BGQC"
   },
   "source": [
    "#### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1418,
     "status": "ok",
     "timestamp": 1580424291763,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "Y3MaIiMlBGQH",
    "outputId": "cb426fe9-8232-4748-ba3a-94db4ca1ea2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor:\n",
    "x = torch.ones(1, requires_grad=True)\n",
    "\n",
    "print(x.grad)    # returns None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iONaddY3BGQP"
   },
   "source": [
    "print(x.grad) is None because a tensor x is a scalar, so there is nothing to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1524,
     "status": "ok",
     "timestamp": 1580424293207,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "2-0Jsk2cBGQR",
    "outputId": "774e1c05-b972-44be-999c-0c0d6eb63d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([84.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1, requires_grad=True)\n",
    "y = 20 + x\n",
    "z = (y ** 2) * 2 \n",
    "z.backward()     # auto gradient calculation\n",
    "\n",
    "print(x.grad)    # ∂z/∂x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rkRXolFfBGQb"
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1580424293988,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "EFpI_dT9BGQf",
    "outputId": "cc687b86-b49f-4db0-e76d-854f5904f198"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"d'aww\", 'match', 'background', 'colour', \"'m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'man', \"'m\", 'really', 'trying', 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'ca', \"n't\", 'make', 'real', 'suggestio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['sir', 'hero', 'chance', 'remember', 'page', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           0  0000997932d777bf   \n",
       "1           1  000103f0d9cfb60f   \n",
       "2           2  000113f07ec002fd   \n",
       "3           3  0001b41b1c6bb37e   \n",
       "4           4  0001d958c54c6e35   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                             cleaned  \n",
       "0  ['explanation', 'edits', 'made', 'username', '...  \n",
       "1  [\"d'aww\", 'match', 'background', 'colour', \"'m...  \n",
       "2  ['hey', 'man', \"'m\", 'really', 'trying', 'edit...  \n",
       "3  ['``', 'ca', \"n't\", 'make', 'real', 'suggestio...  \n",
       "4  ['sir', 'hero', 'chance', 'remember', 'page', ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cTDg0LjBGQp"
   },
   "outputs": [],
   "source": [
    "# Modify labels dtype to 'int', to make summarizing them possible\n",
    "for column in df.columns: \n",
    "    if column not in ['id', 'comment_text', 'cleaned']:\n",
    "        df[column] = df[column].astype('int32')\n",
    "        \n",
    "# Create a toxicity column (sums all of the toxic labels)\n",
    "df['toxicity'] = df.iloc[:,2:8].sum(axis=1)\n",
    "\n",
    "# Clean data - where toxicity is == 0 \n",
    "clean = df[df['toxicity'] == 0]\n",
    "# Messages, which were labelled as obscene\n",
    "obscene = df[df['obscene'] == 1]\n",
    "\n",
    "# Create a dataset for binary classification \n",
    "df_binary = clean.append(obscene, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dplHZtY5BGQx"
   },
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df_binary = df_binary.sample(frac=1)\n",
    "\n",
    "# Reset index of the pd.DataFrame\n",
    "df_binary.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2501,
     "status": "ok",
     "timestamp": 1580424301992,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "gnXaVRgxBGQ4",
    "outputId": "08c01fdd-2b7b-4128-902e-5971654f0a99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38379</td>\n",
       "      <td>42816</td>\n",
       "      <td>723ce83008d61ff5</td>\n",
       "      <td>I'd like to add that a brief read-through of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"'d\", 'like', 'add', 'brief', 'read-through',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99045</td>\n",
       "      <td>110244</td>\n",
       "      <td>4db86bf15466bf82</td>\n",
       "      <td>Whatever is agreed upon, the criteria for incl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['whatever', 'agreed', 'upon', 'criterion', 'i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80938</td>\n",
       "      <td>90159</td>\n",
       "      <td>f145e202ccfefc3c</td>\n",
       "      <td>No personal attacks \\n\\nPlease see Wikipedia's...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['personal', 'attack', 'please', 'see', 'wikip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96632</td>\n",
       "      <td>107547</td>\n",
       "      <td>3ef679a35a575b6e</td>\n",
       "      <td>Wow. \\n\\nHeh....you actually threw the ruleboo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['wow', 'heh', '...', '.you', 'actually', 'thr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129917</td>\n",
       "      <td>144531</td>\n",
       "      <td>0e6cf4f7fdf0c83b</td>\n",
       "      <td>\"\\n\\nKingdom, in addition to being a formal ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'kingdom', 'addition', 'formal', 'title...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Unnamed: 0                id  \\\n",
       "0   38379       42816  723ce83008d61ff5   \n",
       "1   99045      110244  4db86bf15466bf82   \n",
       "2   80938       90159  f145e202ccfefc3c   \n",
       "3   96632      107547  3ef679a35a575b6e   \n",
       "4  129917      144531  0e6cf4f7fdf0c83b   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  I'd like to add that a brief read-through of t...      0             0   \n",
       "1  Whatever is agreed upon, the criteria for incl...      0             0   \n",
       "2  No personal attacks \\n\\nPlease see Wikipedia's...      0             0   \n",
       "3  Wow. \\n\\nHeh....you actually threw the ruleboo...      0             0   \n",
       "4  \"\\n\\nKingdom, in addition to being a formal ti...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \\\n",
       "0        0       0       0              0   \n",
       "1        0       0       0              0   \n",
       "2        0       0       0              0   \n",
       "3        0       0       0              0   \n",
       "4        0       0       0              0   \n",
       "\n",
       "                                             cleaned  toxicity  \n",
       "0  [\"'d\", 'like', 'add', 'brief', 'read-through',...         0  \n",
       "1  ['whatever', 'agreed', 'upon', 'criterion', 'i...         0  \n",
       "2  ['personal', 'attack', 'please', 'see', 'wikip...         0  \n",
       "3  ['wow', 'heh', '...', '.you', 'actually', 'thr...         0  \n",
       "4  ['``', 'kingdom', 'addition', 'formal', 'title...         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 315565,
     "status": "ok",
     "timestamp": 1580424616333,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "c5FEsONUBGRA",
    "outputId": "99fce221-dd65-41d6-d058-31123742551d"
   },
   "outputs": [],
   "source": [
    "# Load W2V model \n",
    "import gensim.downloader as api\n",
    "we_model = KeyedVectors.load_word2vec_format('../task-4/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqIIroE8BGRJ"
   },
   "outputs": [],
   "source": [
    "# Make stratified sampling, for example: select 500 examples with obscene == 1, and 500 clean examples. \n",
    "# Select only a small sample of your data (20%), do not train your model on all of the data available \n",
    "# But to make the task easier, make a stratified selection \n",
    "# (number of 1 labels would be approximately equal to number of 0 labels)\n",
    "''' TASK HERE'''\n",
    "\n",
    "df_sample, _ = train_test_split(df_binary, train_size = 0.35)\n",
    "\n",
    "# Split the data on the stratified training and test data sets \n",
    "''' TASK HERE'''\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df_sample, train_size = 0.75, stratify = df_sample.obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1580424704261,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "9b7g9cfsBGRT",
    "outputId": "2e03bc54-3f35-49b3-f9f1-fbb1773f2e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (39860, 12)\n",
      "Test shape: (13287, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape: {}\".format(df_train.shape))\n",
    "print(\"Test shape: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bKsYP7WuBGRb"
   },
   "outputs": [],
   "source": [
    "def get_vectors(df_sample): \n",
    "    '''\n",
    "    This function would process a DataFrame creating lists of:\n",
    "        vectors, labels and documents corresponding to each raw document. \n",
    "        \n",
    "    Args: \n",
    "        df: pd.DataFrame - DF to vectorize\n",
    "    Returns: \n",
    "        X: list - Vectorized documents, each value in a list is a torch.tensor\n",
    "        labels: list - Labels for each document, each value in a list is a torch.tensor\n",
    "        documents: list - List of the raw texts of the vectorized documents \n",
    "    '''\n",
    "    \n",
    "    # Obtain vectors for documents, vectorized documents list and labels\n",
    "    X, labels, documents = [], [], []\n",
    "    for i, (document, tokens, label) in enumerate(zip(df_sample.comment_text, df_sample.cleaned, df_sample.obscene)):\n",
    "        row_vectors = []\n",
    "        for kw in tokens:\n",
    "            try: \n",
    "                row_vectors.append(we_model[kw])\n",
    "            except (IndexError, KeyError): \n",
    "                continue\n",
    "        if not row_vectors:\n",
    "            continue\n",
    "        row_vectors = np.asarray(row_vectors)\n",
    "        vec = row_vectors.mean(axis=0)\n",
    "        X.append(torch.tensor(vec))\n",
    "        documents.append(document)\n",
    "        labels.append(torch.tensor(label, dtype=torch.float))\n",
    "        \n",
    "    return X, labels, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2EKt_yKBGRj"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, documents_train = get_vectors(df_train)\n",
    "X_test, y_test, documents_test = get_vectors(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lazhoAmBGRq"
   },
   "source": [
    "### How to create a simple NN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J64yR9qYBGRs"
   },
   "outputs": [],
   "source": [
    "# Modify your model to work with batches, not only single item. \n",
    "''' TASK HERE'''\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.logits = nn.Linear(self.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Makes a forward pass \n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        logits = self.logits(relu)\n",
    "        output = self.sigmoid(logits)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1Xcu9YoPPiR"
   },
   "outputs": [],
   "source": [
    "model = FeedForward(300, 200)\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 188483,
     "status": "ok",
     "timestamp": 1580425846712,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "eBcxJ8SoBGR0",
    "outputId": "f15486d6-4cb9-47fe-c292-f78f84c705e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.19708597405089692\n",
      "Epoch 1: train loss: 0.17522358238614974\n",
      "Epoch 2: train loss: 0.1710462270886692\n",
      "Epoch 3: train loss: 0.16885302239600475\n",
      "Epoch 4: train loss: 0.16712328054038061\n",
      "Epoch 5: train loss: 0.16579408220755149\n",
      "Epoch 6: train loss: 0.1646050155009553\n",
      "Epoch 7: train loss: 0.16365620677931808\n",
      "Epoch 8: train loss: 0.16272527350926416\n",
      "Epoch 9: train loss: 0.16195798362504493\n"
     ]
    }
   ],
   "source": [
    "# Initialise the model \n",
    "\n",
    "\n",
    "# Specify loss and optimization functions:\n",
    "\n",
    "# specify loss function\n",
    "criterion = nn.BCELoss()\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "# Move model to the training mode\n",
    "model.train()\n",
    "\n",
    "# init n_epochs \n",
    "n_epochs = 10\n",
    "\n",
    "# init number of iterations for one epoch \n",
    "# we want our model during the epoch to walk trough all of the training examples \n",
    "# for batch_size == 1, number of iterations would be equal to number of examples \n",
    "# in the training set \n",
    "n_iters = len(X_train)\n",
    "\n",
    "# initialise batch_size\n",
    "# NOTE! for now it's equal == 1, you need to modify your model to make it possible to work with \n",
    "# batches during training, not only making an update for a single example \n",
    "batch_size = 1\n",
    "for epoch in range(n_epochs):  \n",
    "    epoch_loss = 0\n",
    "    for idx in range(n_iters):\n",
    "        \n",
    "        # Selects only 1 sample, modify it to select N samples, N == batch_size\n",
    "        ''' TASK HERE'''\n",
    "        # idx = random.sample(range(len(X_train)), 1) # TIP: You can random sample N examples \n",
    "        \n",
    "        optimizer.zero_grad()    # Forward pass\n",
    "\n",
    "        # Select corresponding data from:\n",
    "        # X (vectors) and labels - for calculating the loss and making a backward pass \n",
    "        # backward pass - updating our weights according to the obtained loss \n",
    "        ''' TASK HERE'''\n",
    "        x = X_train[idx]\n",
    "        y_true = y_train[idx]\n",
    "        \n",
    "        #x = x.to(device)\n",
    "        #y_true = y_true.to(device)\n",
    "\n",
    "        y_pred = model(x)    # Compute Loss\n",
    "        loss = criterion(y_pred.squeeze(), y_true)\n",
    "        \n",
    "        epoch_loss += loss.item() / n_iters\n",
    "        loss.backward()   # Backward pass \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch {}: train loss: {}'.format(epoch, epoch_loss))    # Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7fXDJlodBGR9"
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, X_test, y_test, documents_test, threshold): \n",
    "    n_prints = 0\n",
    "    preds = []\n",
    "    for example, label, document in zip(X_test, y_test, documents_test):\n",
    "        pred = model(example)\n",
    "        y_pred = int(pred.item() > threshold)\n",
    "        preds.append(y_pred)\n",
    "        \n",
    "        # Print some examples with obscene documents texts and predicted and true labels \n",
    "        if label.item() == 1.0 and n_prints < 10:\n",
    "            print(\"Predicted label: {}\".format(y_pred))\n",
    "            print(\"True label: {}\".format(label.item()))\n",
    "            print(\"Document: {}\".format(document))\n",
    "            print(\"*-*-\"*20)\n",
    "            n_prints += 1\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3048,
     "status": "ok",
     "timestamp": 1580425919081,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "FpEp2GxyBGSK",
    "outputId": "13364909-5e74-4363-837c-cf124f60954b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: look here \n",
      "\n",
      "your a fuckin cunt you czeckoslovacian ass clown\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: How does it feel to be a stupid bitch who edits wikipedia? too bad nobody will ever love you\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Whos the douche that deleated all of the info and crap I really want to curse them out right now.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: fuck off mifter \n",
      "\n",
      "that was a great edit!!!! it was about icecream!!!!\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: AT \n",
      "\n",
      "Have you bookmarked ｗｗｗ．ＡｎｏｎＴａｌｋ．ｃｏｍ yet? It's sort of like Wikipeda's refdesk, except it doesn't suck.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Accept what\n",
      "Accept what, you putting your dick up someones ass.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: FUCKING LAMER LOSTING OF MY TIME !!JOADFYH \n",
      "\n",
      "You are wasting my time fucker. Please provide me the fucking information to add the fucking tag to add that this is my image, that I give it to everyone for free and that I owned the fucking copyright. THIS IS SO COMPLICATED TO DONATE AN IMAGE TO WIKIPEDIA THIS IS MY FUCKING SOURCE MY FUCKING IMAGE. fucker.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: \"\n",
      "\n",
      " FCUK YOU DOC \n",
      "\n",
      "  The Anti-Vandalism BarnstarFUKU  122.111.252.2  \"\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: WHAT A FUCKING RIOT!!!  I AM LAUGHING MY SWEET WHITE ASS OFF!!!!\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: GET SOME GLASSES YOU MENTAL FAGOTs, IM Calling you the idiots SHITheads!!!!! What the F@#%k is wrong with you.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "source": [
    "# Move model to the eval mode before making a prediction\n",
    "model.eval()\n",
    "preds = make_predictions(model, X_test, y_test, documents_test, threshold=0.5)\n",
    "\n",
    "test_labels = [label.item() for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3488,
     "status": "ok",
     "timestamp": 1580425926174,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "FL7gteP9Sc_E",
    "outputId": "217ce187-fd60-4e51-a390-d75f514eb469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     12546\n",
      "         1.0       0.80      0.21      0.34       739\n",
      "\n",
      "    accuracy                           0.95     13285\n",
      "   macro avg       0.88      0.60      0.66     13285\n",
      "weighted avg       0.95      0.95      0.94     13285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTZtxGDMBGSR",
    "outputId": "a83acbc7-928b-4fb7-a018-de69acc99b45",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results to beat:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|         | precision | recall | f1-score | support |\n",
    "|---------|-----------|--------|----------|---------|\n",
    "|0.0      |0.98       |0.99    |0.99      |5724     |\n",
    "|1.0      |0.87       |0.62    |0.72      |337      |\n",
    "|acc      |           |        |0.97      |6061     |\n",
    "|macro avg|0.92       |0.81    |0.86      |6061     |\n",
    "|wghtn avg|0.97       |0.97    |0.97      |6061     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyaDBaimBGSY"
   },
   "source": [
    "## Task 1: \n",
    "\n",
    "#### Find all of the ''' TASK HERE ''' messages. \n",
    "\n",
    "1. Create stratified dataset, make your classes balanced! Train the model. Try to beat the initial score.\n",
    "\n",
    "2. While vectorizing by W2V model, add tf-idf weightning, look at TfidfVectorizer at sklearn. \n",
    "\n",
    "3. Add batch size, modify your model architecture to make it possible to process batches, not only single items. \n",
    "\n",
    "4. Change hidden_size, n_layers, activation function, etc to modify your model. \n",
    "\n",
    "5. Tweak learning rate, see what happened if LR is too small, if too big (0.0001 / 0.8 for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uZidQEdBGSa"
   },
   "outputs": [],
   "source": [
    "# Tip:\n",
    "# Use tf-idf scores calculated by sklearn:\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    # This function is used to replace a default tokenizer in sklearn. \n",
    "    # If you are passing a tokenized documents to the tf-idf vectorizer - \n",
    "    # it would be much faster \n",
    "    return doc\n",
    "\n",
    "def get_idf(tokenized_docs, max_features=180000):\n",
    "    ''' Returns a tf-idf dictionary: \n",
    "            key: word,\n",
    "            value: tf-idf score. \n",
    "    '''\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        min_df=3,\n",
    "        max_features=max_features,\n",
    "        analyzer='word',\n",
    "        tokenizer=dummy_fun,\n",
    "        preprocessor=dummy_fun,\n",
    "        token_pattern=None,\n",
    "        ngram_range=(1, 1))\n",
    "\n",
    "    vectorizer.fit(tokenized_docs)\n",
    "    idf_dict = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "    \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8a5tndQTzT71"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def get_vectors_modified(df_sample): \n",
    "    '''\n",
    "    This function would process a DataFrame creating lists of:\n",
    "        vectors, labels and documents corresponding to each raw document. \n",
    "        \n",
    "    Args: \n",
    "        df: pd.DataFrame - DF to vectorize\n",
    "    Returns: \n",
    "        X: list - Vectorized documents, each value in a list is a torch.tensor\n",
    "        labels: list - Labels for each document, each value in a list is a torch.tensor\n",
    "        documents: list - List of the raw texts of the vectorized documents \n",
    "    '''\n",
    "    idf_dictionary = get_idf([literal_eval(t) for t in df_sample.cleaned])\n",
    "    #print(idf_dictionary)\n",
    "    # Obtain vectors for documents, vectorized documents list and labels\n",
    "    X, labels, documents = [], [], []\n",
    "    for i, (document, tokens, label) in enumerate(zip(df_sample.comment_text, df_sample.cleaned, df_sample.obscene)):\n",
    "        row_vectors = []\n",
    "        for kw in tokens:\n",
    "            try: \n",
    "                row_vectors.append(we_model[kw] * idf_dictionary[kw])\n",
    "            except (IndexError, KeyError): \n",
    "                continue\n",
    "        if not row_vectors:\n",
    "            continue\n",
    "        row_vectors = np.asarray(row_vectors)\n",
    "        vec = row_vectors.mean(axis=0)\n",
    "        X.append(torch.tensor(vec))\n",
    "        documents.append(document)\n",
    "        labels.append(torch.tensor(label, dtype=torch.float))\n",
    "        \n",
    "    return X, labels, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53288,
     "status": "ok",
     "timestamp": 1580427743606,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "utdl4VsS0GPF",
    "outputId": "7b3e7799-8d90-4ead-aebc-3ee0b2b54c8b"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, documents_train = get_vectors_modified(df_train)\n",
    "X_test, y_test, documents_test = get_vectors_modified(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWpoc_KImkCH"
   },
   "outputs": [],
   "source": [
    "class FeedForwardModified(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size_1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.hidden_size_1 = hidden_size_1\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size_1)\n",
    "        self.fc2 = nn.Linear(self.hidden_size_1, 1)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_1 = self.fc1(x)\n",
    "        hidden_1_a = self.relu(hidden_1)\n",
    "        \n",
    "        pre_output = self.fc2(hidden_1_a)\n",
    "        output = self.sigmoid(pre_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSyHTIbqmvJl"
   },
   "outputs": [],
   "source": [
    "model = FeedForwardModified(300, 150)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.005)\n",
    "\n",
    "model.train()\n",
    "\n",
    "if isinstance(X_train, list) and isinstance(y_train, list):\n",
    "    X_train = torch.stack(X_train)\n",
    "    y_train = torch.stack(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.1445094387909887\n",
      "Epoch 1: train loss: 0.14352081649915577\n",
      "Epoch 2: train loss: 0.1430677275369563\n",
      "Epoch 3: train loss: 0.14231949657810164\n",
      "Epoch 4: train loss: 0.14175274099819637\n",
      "Epoch 5: train loss: 0.14111572692850707\n",
      "Epoch 6: train loss: 0.1401469257734884\n",
      "Epoch 7: train loss: 0.1396836246414583\n",
      "Epoch 8: train loss: 0.13913034881155584\n",
      "Epoch 9: train loss: 0.1384585494750251\n",
      "Epoch 10: train loss: 0.13753231617585807\n",
      "Epoch 11: train loss: 0.13708788302166905\n",
      "Epoch 12: train loss: 0.1365998728555266\n",
      "Epoch 13: train loss: 0.13626558077823145\n",
      "Epoch 14: train loss: 0.1356228358378412\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-3de6b4265499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "n_iters = len(X_train)\n",
    "\n",
    "batch_size = 300\n",
    "\n",
    "for epoch in range(n_epochs):  \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        idx = random.sample(range(len(X_train)), batch_size)\n",
    "        x = X_train[idx]\n",
    "        y_true = y_train[idx]\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred.squeeze(), y_true)\n",
    "        epoch_loss += loss.item() / n_iters\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoch {}: train loss: {}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1764,
     "status": "error",
     "timestamp": 1580430477881,
     "user": {
      "displayName": "Daniel The Human",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBUmMy579YAVePyM-d7M5a9AuelZcd0sWL1969gVw=s64",
      "userId": "18199465969344515242"
     },
     "user_tz": -120
    },
    "id": "zoWGUR7cnl_d",
    "outputId": "7ad84bcb-acdf-4a7b-a9b7-80b87f95f9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: look here \n",
      "\n",
      "your a fuckin cunt you czeckoslovacian ass clown\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: How does it feel to be a stupid bitch who edits wikipedia? too bad nobody will ever love you\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Whos the douche that deleated all of the info and crap I really want to curse them out right now.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: fuck off mifter \n",
      "\n",
      "that was a great edit!!!! it was about icecream!!!!\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: AT \n",
      "\n",
      "Have you bookmarked ｗｗｗ．ＡｎｏｎＴａｌｋ．ｃｏｍ yet? It's sort of like Wikipeda's refdesk, except it doesn't suck.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 0\n",
      "True label: 1.0\n",
      "Document: Accept what\n",
      "Accept what, you putting your dick up someones ass.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: FUCKING LAMER LOSTING OF MY TIME !!JOADFYH \n",
      "\n",
      "You are wasting my time fucker. Please provide me the fucking information to add the fucking tag to add that this is my image, that I give it to everyone for free and that I owned the fucking copyright. THIS IS SO COMPLICATED TO DONATE AN IMAGE TO WIKIPEDIA THIS IS MY FUCKING SOURCE MY FUCKING IMAGE. fucker.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: \"\n",
      "\n",
      " FCUK YOU DOC \n",
      "\n",
      "  The Anti-Vandalism BarnstarFUKU  122.111.252.2  \"\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: WHAT A FUCKING RIOT!!!  I AM LAUGHING MY SWEET WHITE ASS OFF!!!!\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Predicted label: 1\n",
      "True label: 1.0\n",
      "Document: GET SOME GLASSES YOU MENTAL FAGOTs, IM Calling you the idiots SHITheads!!!!! What the F@#%k is wrong with you.\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = make_predictions(model, X_test, y_test, documents_test, threshold=0.5)\n",
    "test_labels = [label.item() for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98     12546\n",
      "         1.0       0.78      0.34      0.47       739\n",
      "\n",
      "    accuracy                           0.96     13285\n",
      "   macro avg       0.87      0.67      0.72     13285\n",
      "weighted avg       0.95      0.96      0.95     13285\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9579224689499436"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(test_labels, preds))\n",
    "accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы увидим в дальнейшем, качество обучения нейронной сети зависит от параметра learning rate. Покажем, что с большим значением результаты будут неудовлетворительными, а с достаточно низким - долгое время тренировки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Только после того, как Дан научится кодить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdj4E3D5BGSh"
   },
   "source": [
    "## Task 2, advanced\n",
    "\n",
    "Working with nn.Embedding layer \n",
    "\n",
    "https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html \n",
    "\n",
    "Read an example below. \n",
    "\n",
    "Please, try to modify your initial version of the SingleLayerPerceptron model to the model with one additional layer: \n",
    "\n",
    "1. Define your vocabulary size  \n",
    "2. Add nn.Embedding layer to the model architecture (vocabulary_size, embedding_size) \n",
    "3. Retrain your model - see if metrics increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyMP9FAuBGSj"
   },
   "source": [
    "### Useful parts for the part 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0JA6aFDBGSn"
   },
   "source": [
    "Refer  to the part 4.3 of the course:\n",
    "\n",
    "https://stepik.org/lesson/262247/\n",
    "\n",
    "It will help you to get the understanding how to use an nn.Embedding layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEf2AuG_BGSq"
   },
   "source": [
    "#####  Let's create a vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUh8Sk3qBGSu"
   },
   "outputs": [],
   "source": [
    "def flat_nested(nested):\n",
    "    flatten = []\n",
    "    for item in nested:\n",
    "        if isinstance(item, list):\n",
    "            flatten.extend(item)\n",
    "        else:\n",
    "            flatten.append(item)\n",
    "    return flatten\n",
    "\n",
    "cnt_vocab = Counter(flat_nested(df.cleaned.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etFoZNG8BGS0",
    "outputId": "fc88eb41-2df6-46c7-d018-8f177874accc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 13061\n"
     ]
    }
   ],
   "source": [
    "threshold_count_l = 15\n",
    "threshold_count_h = 500\n",
    "threshold_len = 4\n",
    "cleaned_vocab = [token for token, count in cnt_vocab.items() if \n",
    "                     threshold_count_h > count > threshold_count_l and len(token) > threshold_len\n",
    "                ]\n",
    "print(\"Vocab size: {}\".format(len(cleaned_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjyk-id_BGS7"
   },
   "outputs": [],
   "source": [
    "# You will need to have an id for each of your token \n",
    "\n",
    "token_to_id = {v: k for k, v in enumerate(sorted(cleaned_vocab))}\n",
    "id_to_token = {v: k for k, v in token_to_id.items()}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task-28_29-01-2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
