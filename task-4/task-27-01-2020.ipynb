{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models import FastText\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numexpr as ne\n",
    "\n",
    "ne.set_num_threads(ne.detect_number_of_cores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tokenizer, lemmatizer, stop_words, punctuation, text): \n",
    "    tokens = tokenizer(text.lower())\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return [token for token in lemmas if token not in stop_words and token not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_load = True\n",
    "\n",
    "if not bool_load:\n",
    "    df['cleaned'] = df.comment_text.apply(lambda x: preprocess_text(word_tokenize, lemmatizer, stop_words, punctuation, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_save = False\n",
    "\n",
    "if bool_save:\n",
    "    df.to_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24039</th>\n",
       "      <td>24039</td>\n",
       "      <td>3f7df081f41a7ea3</td>\n",
       "      <td>Also, the preview is free.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['also', 'preview', 'free']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107340</th>\n",
       "      <td>107340</td>\n",
       "      <td>3dccfe67cbc88d80</td>\n",
       "      <td>Irrelevancy, unconnectedness, competition to b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['irrelevancy', 'unconnectedness', 'competitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87489</th>\n",
       "      <td>87489</td>\n",
       "      <td>ea0d65e2c36e8d21</td>\n",
       "      <td>How am I supposed to test how redirecting work...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['supposed', 'test', 'redirecting', 'work', 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159053</th>\n",
       "      <td>159053</td>\n",
       "      <td>f7be51022c3e60bf</td>\n",
       "      <td>How rude \\n\\nSeriously? My sillypeppymacspeed ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['rude', 'seriously', 'sillypeppymacspeed', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106724</th>\n",
       "      <td>106724</td>\n",
       "      <td>3acf61c2d1ec75ec</td>\n",
       "      <td>\"\\nThat 'Wada's Memory' is lovely. Most around...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', \"'wada\", \"'s\", 'memory', 'lovely', 'aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                id  \\\n",
       "24039        24039  3f7df081f41a7ea3   \n",
       "107340      107340  3dccfe67cbc88d80   \n",
       "87489        87489  ea0d65e2c36e8d21   \n",
       "159053      159053  f7be51022c3e60bf   \n",
       "106724      106724  3acf61c2d1ec75ec   \n",
       "\n",
       "                                             comment_text  toxic  \\\n",
       "24039                          Also, the preview is free.      0   \n",
       "107340  Irrelevancy, unconnectedness, competition to b...      0   \n",
       "87489   How am I supposed to test how redirecting work...      0   \n",
       "159053  How rude \\n\\nSeriously? My sillypeppymacspeed ...      1   \n",
       "106724  \"\\nThat 'Wada's Memory' is lovely. Most around...      0   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "24039              0        0       0       0              0   \n",
       "107340             0        0       0       0              0   \n",
       "87489              0        0       0       0              0   \n",
       "159053             0        1       0       0              0   \n",
       "106724             0        0       0       0              0   \n",
       "\n",
       "                                                  cleaned  \n",
       "24039                         ['also', 'preview', 'free']  \n",
       "107340  ['irrelevancy', 'unconnectedness', 'competitio...  \n",
       "87489   ['supposed', 'test', 'redirecting', 'work', 's...  \n",
       "159053  ['rude', 'seriously', 'sillypeppymacspeed', 'p...  \n",
       "106724  ['``', \"'wada\", \"'s\", 'memory', 'lovely', 'aro...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our first model based on the vocabulary from df_sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With initialization model trained for 5 epochs \n",
    "\n",
    "df_sample_cleaned_list = [literal_eval(s) for s in df_sample.cleaned.tolist()]\n",
    "\n",
    "model = Word2Vec(sentences=df_sample_cleaned_list, \n",
    "         size=100,      # embedding vector size\n",
    "         min_count=5,   # consider words that occured at least 5 times\n",
    "         window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100574369, 118974570)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue training the model \n",
    "\n",
    "model.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=30\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab # to look at vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thing', 0.6192317008972168),\n",
       " ('others', 0.6143143177032471),\n",
       " ('person', 0.581950843334198),\n",
       " ('everyone', 0.5551775693893433),\n",
       " ('editor', 0.5309818983078003),\n",
       " ('personally', 0.527014970779419),\n",
       " ('guy', 0.5265326499938965),\n",
       " ('anyone', 0.5155367255210876),\n",
       " ('way', 0.5107394456863403),\n",
       " ('individual', 0.5079406499862671)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next approach is to try to use the already pretrained model, which can be downloaded from here:\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim-data\n",
    "\n",
    "model:   \n",
    "GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\n",
    "    os.getcwd() + os.sep + \"GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try to use GloVe model too and experiment with it: <- later\n",
    "# import gensim.downloader as api\n",
    "# model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Cosine similarity\n",
    "\n",
    "To measure how similar two words are, we need a way to measure the degree of similarity between two embedding vectors for the two words. Given two vectors $u$ and $v$, cosine similarity is defined as follows: \n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u . v} {||u||_2 ||v||_2} = cos(\\theta) \\tag{1}$$\n",
    "\n",
    "where $u.v$ is the dot product (or inner product) of two vectors, $||u||_2$ is the norm (or length) of the vector $u$, and $\\theta$ is the angle between $u$ and $v$. This similarity depends on the angle between $u$ and $v$. If $u$ and $v$ are very similar, their cosine similarity will be close to 1; if they are dissimilar, the cosine similarity will take a smaller value. \n",
    "\n",
    "<img src=\"cosine_sim.png\" style=\"width:800px;height:250px;\">\n",
    "<caption><center> **Figure 1**: The cosine of the angle between two vectors is a measure of how similar they are</center></caption>\n",
    "\n",
    "**Exercise**: Implement the function `cosine_similarity()` to evaluate similarity between word vectors.\n",
    "\n",
    "**Reminder**: The norm of $u$ is defined as $ ||u||_2 = \\sqrt{\\sum_{i=1}^{n} u_i^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(w1, w2):\n",
    "    \"\"\"\n",
    "    Cosine similarity between w1 and w2\n",
    "    \n",
    "    Arguments:\n",
    "        w1 : word vector        \n",
    "        w2 : word vector \n",
    "    Returns:\n",
    "        cosine_similarity \n",
    "    \"\"\"\n",
    "    if (not np.any(w1) or not np.any(w2)): # check input is not zero-vector\n",
    "        return 0\n",
    "    \n",
    "    # Dot product between w1 and w2\n",
    "    dot = np.dot(w1, w2)\n",
    "    # L2 norm of w1\n",
    "    norm_u = np.linalg.norm(w1) \n",
    "    # L2 norm of w2 \n",
    "    norm_v = np.linalg.norm(w2) \n",
    "    # Cosine similarity \n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "father = model.get_vector(\"father\")\n",
    "mother = model.get_vector(\"mother\")\n",
    "\n",
    "ball = model.get_vector(\"ball\")\n",
    "crocodile = model.get_vector(\"crocodile\")\n",
    "\n",
    "france = model.get_vector(\"france\")\n",
    "paris = model.get_vector(\"paris\")\n",
    "italy = model.get_vector(\"italy\")\n",
    "rome = model.get_vector(\"rome\")\n",
    "\n",
    "kiev = model.get_vector(\"kiev\")\n",
    "ukraine = model.get_vector(\"ukraine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.79014826\n",
      "cosine_similarity(ball, crocodile) =  0.10283584\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.1988747\n",
      "cosine_similarity(kiev, ukraine) =  0.3738725\n"
     ]
    }
   ],
   "source": [
    "fast_print = lambda u, v, tag1, tag2: print(\n",
    "    \"cosine_similarity({t1}, {t2}) = \".format(t1 = tag1, t2 = tag2), cosine_similarity(u, v)\n",
    ")\n",
    "\n",
    "fast_print(father, mother, \"father\", \"mother\")\n",
    "fast_print(ball, crocodile, \"ball\", \"crocodile\")\n",
    "fast_print(france - paris, rome - italy, \"france - paris\", \"rome - italy\")\n",
    "fast_print(kiev, ukraine, \"kiev\", \"ukraine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approximate expected output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(father, mother)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.79014826\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(ball, crocodile)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.10283585\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(france - paris, rome - italy)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         -0.421037\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Word analogy task\n",
    "\n",
    "In the word analogy task, we complete the sentence <font color='brown'>\"*a* is to *b* as *c* is to **____**\"</font>. An example is <font color='brown'> '*man* is to *woman* as *king* is to *queen*' </font>. In detail, we are trying to find a word *d*, such that the associated word vectors $e_a, e_b, e_c, e_d$ are related in the following manner: $e_b - e_a \\approx e_d - e_c$. We will measure the similarity between $e_b - e_a$ and $e_d - e_c$ using cosine similarity. \n",
    "\n",
    "**Exercise**: Complete the code below to be able to perform word analogies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note***: here you will need to complete a function in the sections, which are marked as:\n",
    "\n",
    "```\n",
    "# ----- Start ----- #\n",
    "Your code should be written in-between the lines\n",
    "# ------ End ------ #\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_analogy(word_1, word_2, word_3, model):\n",
    "    \"\"\"\n",
    "    Finds the word to complete analogy (see explanation above): a is to b as c is to ____. \n",
    "    \n",
    "    Arguments:\n",
    "    word_1 -- a word, string\n",
    "    word_2 -- a word, string\n",
    "    word_3 -- a word, string\n",
    "    model -- word embeddings model \n",
    "    \n",
    "    Returns:\n",
    "    best_word --  the word such that v_1 - v_2 is close to v_best_word - v_3, as measured by cosine similarity\n",
    "    \"\"\"\n",
    "    # convert words to lower case\n",
    "    word_1, word_2, word_3 = word_1.lower(), word_2.lower(), word_3.lower()\n",
    "    \n",
    "    # ----- Start ----- #\n",
    "    # Get the word embeddings v_a, v_b and v_c (â‰ˆ1-3 lines)\n",
    "    fast_get = lambda word: model.get_vector(word)\n",
    "    e_1, e_2, e_3 = tuple(map(fast_get, [word_1, word_2, word_3]))\n",
    "    # ------ End ------ #\n",
    "    \n",
    "    words = list(model.vocab.keys())\n",
    "    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n",
    "    best_word = None                   # Initialize best_word with None\n",
    "\n",
    "    # Loop over the whole word vector set\n",
    "    for w in words:        \n",
    "        e_j = fast_get(w)\n",
    "        # to avoid best_word being one of the input words, skip them and continue iteration.\n",
    "        if w in [word_1, word_2, word_3]:\n",
    "            continue\n",
    "        \n",
    "        # ----- Start ----- #\n",
    "        # Compute cosine similarity between the vector (e_2 - e_1) and the vector ((w's vector) - e_3)\n",
    "        cosine_sim = cosine_similarity(e_2 - e_1, e_j - e_3)\n",
    "        \n",
    "        # If the cosine_sim is more than the max_cosine_sim seen so far,\n",
    "        # do not forget to set new max_cosine_sim to the current value and best_word as well\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        # ------ End ------ #\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man -> woman :: king -> queen\n",
      "bad -> good :: sad -> wonderful\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [\n",
    "    ('man', 'woman', 'king'), \n",
    "    ('bad', 'good', 'sad'), \n",
    "    ('man', 'woman', 'boy'), \n",
    "    ('small', 'smaller', 'large')\n",
    "]\n",
    "\n",
    "for triad in triads_to_try:\n",
    "    print('{} -> {} :: {} -> {}'.format(*triad, find_word_analogy(*triad, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **man -> woman** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         king -> queen\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **bad -> good** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         sad -> wonderful\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **man -> woman ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         boy -> girl\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **small -> smaller ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         large -> larger\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next part of the task is to:  \n",
    "\n",
    "1. Train your own W2V model using the proposed method above. Use all of the tokens created after your preprocessing pipeline in the previous tasks. (deleting stop_words, punctuation, lowercasing, etc - play as you want).  \n",
    "2. Use obtained vectors to obtain text vectors using such pipeline: \n",
    "  1. For each word in a preprocessed text, get a word vector from the W2V model. \n",
    "  2. Add them together to obtain vectors for texts (sum them together, or get mean vector) \n",
    "3. Use obtained text vectors as a text representation to perform a text classification task.  \n",
    "   Proposed - use binary classification (for example: select only 'obscene' text and clean and try to distinguish them one from another)\n",
    "4. Calculate the metrics - TP, FP, FN, TN, precision, recall, F1 score, F2 score, accurary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class callback_custom(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "         self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Iteration {:3}\".format(self.epoch+1))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   1\n",
      "Iteration   2\n",
      "Iteration   3\n",
      "Iteration   4\n",
      "Iteration   5\n"
     ]
    }
   ],
   "source": [
    "# init w2v model\n",
    "n_dimensions = 300\n",
    "\n",
    "model_w2v = Word2Vec(sentences=df_sample_cleaned_list, \n",
    "                     size=n_dimensions, min_count=5, window=5,\n",
    "                     callbacks=[callback_custom()]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   6\n",
      "Iteration   7\n",
      "Iteration   8\n",
      "Iteration   9\n",
      "Iteration  10\n",
      "Iteration  11\n",
      "Iteration  12\n",
      "Iteration  13\n",
      "Iteration  14\n",
      "Iteration  15\n",
      "Iteration  16\n",
      "Iteration  17\n",
      "Iteration  18\n",
      "Iteration  19\n",
      "Iteration  20\n",
      "Iteration  21\n",
      "Iteration  22\n",
      "Iteration  23\n",
      "Iteration  24\n",
      "Iteration  25\n",
      "Iteration  26\n",
      "Iteration  27\n",
      "Iteration  28\n",
      "Iteration  29\n",
      "Iteration  30\n",
      "Iteration  31\n",
      "Iteration  32\n",
      "Iteration  33\n",
      "Iteration  34\n",
      "Iteration  35\n",
      "Iteration  36\n",
      "Iteration  37\n",
      "Iteration  38\n",
      "Iteration  39\n",
      "Iteration  40\n",
      "Iteration  41\n",
      "Iteration  42\n",
      "Iteration  43\n",
      "Iteration  44\n",
      "Iteration  45\n",
      "Iteration  46\n",
      "Iteration  47\n",
      "Iteration  48\n",
      "Iteration  49\n",
      "Iteration  50\n",
      "Iteration  51\n",
      "Iteration  52\n",
      "Iteration  53\n",
      "Iteration  54\n",
      "Iteration  55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(167618003, 198290950)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "number_of_iterations = 50\n",
    "\n",
    "model_w2v.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model_w2v.corpus_count,\n",
    "            epochs=number_of_iterations\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('others', 0.5339361429214478),\n",
       " ('thing', 0.5025500059127808),\n",
       " ('way', 0.4797881543636322),\n",
       " ('person', 0.4717697203159332),\n",
       " (\"n't\", 0.4668528437614441),\n",
       " ('would', 0.4465913474559784),\n",
       " (\"'re\", 0.4391423165798187),\n",
       " ('editor', 0.4381656348705292),\n",
       " ('everyone', 0.4344182014465332),\n",
       " ('really', 0.43325215578079224)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"n't\", 0.49487966299057007),\n",
       " ('two', 0.47774815559387207),\n",
       " (\"'s\", 0.46667248010635376),\n",
       " ('way', 0.4609620273113251),\n",
       " ('even', 0.457366943359375),\n",
       " ('think', 0.4486578106880188),\n",
       " ('article', 0.4449920356273651),\n",
       " ('thing', 0.4265356659889221),\n",
       " ('would', 0.419446736574173),\n",
       " ('every', 0.41300418972969055)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_save_model = False\n",
    "\n",
    "if bool_save_model:\n",
    "    model_w2v.wv.save_word2vec_format('w2v_df_t2_clnd_sample.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v_vectors = model_w2v.wv # getting keyed vectors from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building text vectors\n",
    "def tf(words_from_text, word):\n",
    "    return words_from_text.count(word) / len(words_from_text)\n",
    "\n",
    "\n",
    "def idf(corpus, word): # basic formula, not sklearn modification\n",
    "    return np.log(len(corpus) / (np.sum(pd.Series(corpus).apply(lambda l: word in l).sum()) + 1)) # ineffective actually\n",
    "\n",
    "\n",
    "def tf_idf(corpus, words_from_text, word):\n",
    "    return tf(words_from_text, word) * idf(corpus, word)\n",
    "\n",
    "\n",
    "def form_text_vector(words_from_text, w2v_model_keyed_vectors, num_dim, weightened = False, corpus = None):\n",
    "    text_vectorized = np.zeros(num_dim)\n",
    "    for word in words_from_text:\n",
    "        try:\n",
    "            q = tf_idf(corpus, words_from_text, word) if weightened else 1\n",
    "            v = w2v_model_keyed_vectors.get_vector(word)\n",
    "            s = ne.evaluate('q * v')\n",
    "            text_vectorized = ne.evaluate('text_vectorized + s') \n",
    "        except KeyError:\n",
    "            continue\n",
    "    return text_vectorized\n",
    "\n",
    "\n",
    "def form_corpus_matrix(corpus, w2v_model_keyed_vectors, num_dim, weightened = False):\n",
    "    corpus_len = len(corpus)\n",
    "    corpus_vectorized = np.empty((corpus_len, num_dim))\n",
    "    for j in range(corpus_len):\n",
    "        corpus_vectorized[j] = form_text_vector(\n",
    "            corpus[j], w2v_model_keyed_vectors, num_dim, weightened, (corpus if weightened else None)\n",
    "        )\n",
    "    return corpus_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              texts\n",
      "0      1           ['cocksucker', 'piss', 'around', 'work']\n",
      "1      1  ['gay', 'antisemmitian', 'archangel', 'white',...\n",
      "2      1                ['fuck', 'filthy', 'mother', 'dry']\n",
      "3      1  ['stupid', 'peace', 'shit', 'stop', 'deleting'...\n",
      "4      1  ['=tony', 'sidaway', 'obviously', 'fistfuckee'...\n",
      "\n",
      "        label                                              texts\n",
      "151218      0  ['``', 'second', 'time', 'asking', 'view', 'co...\n",
      "151219      0  ['ashamed', 'horrible', 'thing', 'put', 'talk'...\n",
      "151220      0  ['spitzer', 'umm', 'actual', 'article', 'prost...\n",
      "151221      0  ['look', 'like', 'wa', 'actually', 'put', 'spe...\n",
      "151222      0  ['``', '...', 'really', \"n't\", 'think', 'under...\n"
     ]
    }
   ],
   "source": [
    "text_categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cleaned']\n",
    "\n",
    "temp = df[[text_categories[4], text_categories[-1]]]\n",
    "\n",
    "temp_n = temp[~df[text_categories[:-1]].any(axis = 'columns')]\n",
    "temp_i = temp[df.insult != 0]\n",
    "\n",
    "insulting_and_neutral = temp_i.append(temp_n).reset_index(drop = True)\n",
    "insulting_and_neutral.columns = ['label', 'texts']\n",
    "\n",
    "del temp, temp_n, temp_i\n",
    "\n",
    "print(\n",
    "    insulting_and_neutral.head(),\n",
    "    insulting_and_neutral.tail(),\n",
    "    sep = '\\n\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.25\n",
    "\n",
    "X_train_t, X_test_t, Y_train, Y_test = train_test_split(\n",
    "    insulting_and_neutral['texts'], insulting_and_neutral['label'],\n",
    "    test_size = P,\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "X_train_t = [literal_eval(s) for s in X_train_t.reset_index(drop = True)]\n",
    "X_test_t = [literal_eval(s) for s in X_test_t.reset_index(drop = True)]\n",
    "\n",
    "Y_train = Y_train.reset_index(drop = True)\n",
    "Y_test = Y_test.reset_index(drop = True)\n",
    "\n",
    "X_train = form_corpus_matrix(X_train_t, model_w2v_vectors, n_dimensions)\n",
    "X_test = form_corpus_matrix(X_test_t, model_w2v_vectors, n_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-12.35104467,  -8.17274323, -18.59831111, ...,  36.7983124 ,\n",
       "         12.52592548,  21.1039791 ],\n",
       "       [ -2.81955897,  -9.69962908,   1.88148963, ...,  13.642529  ,\n",
       "        -10.04428923,   8.03920545],\n",
       "       [ -9.11592402, -28.60746697,  35.92750233, ...,  30.51325954,\n",
       "          3.75637635,  13.571417  ],\n",
       "       ...,\n",
       "       [ -0.21584964,   1.16181156,   0.79537393, ...,   2.31340441,\n",
       "          3.00284505,   1.15497546],\n",
       "       [ -6.83088657,  -2.82277148,   0.39542336, ...,   6.32051712,\n",
       "         -3.15185402,   0.97580142],\n",
       "       [ -1.00793014, -11.55683097,  -6.5866206 , ...,  10.05888395,\n",
       "        -15.74624236,  -0.84744722]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.78701475,  -2.72190091,   6.90805295, ...,   3.40705891,\n",
       "         -0.07042353,  -2.67172024],\n",
       "       [ -1.9286124 ,  -7.5543409 ,  -2.27088131, ...,  11.60221306,\n",
       "         -5.56597029,  18.59090474],\n",
       "       [ -8.52430123,  -9.59827719,   9.66561522, ...,  21.28244998,\n",
       "         -5.42605857,  21.43395831],\n",
       "       ...,\n",
       "       [ -4.06618702,  -4.77386539,   4.74683376, ...,   5.4642067 ,\n",
       "         -4.91882995,   6.47815394],\n",
       "       [-14.36065287, -11.67583142,   1.646921  , ...,  24.40385153,\n",
       "         -6.56671622,  26.26983546],\n",
       "       [  2.70304674,   1.84420886,   1.20486937, ...,   3.22635186,\n",
       "         -1.07491895,  -0.12592049]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_report(y_test, y_prediction):\n",
    "    confusion_matr = confusion_matrix(y_test, y_prediction)\n",
    "    print(\"CONFUSION MATRIX:\\n{matr}\".format(matr=confusion_matr))\n",
    "    accuracy_of_model = accuracy_score(y_test, y_prediction)\n",
    "    print(\"ACCURACY:\\n{acc}\".format(acc = accuracy_of_model))\n",
    "    sklearn_report = classification_report(y_test, y_prediction)\n",
    "    print(\"TABLE:\\n{tab}\".format(tab=sklearn_report))\n",
    "\n",
    "# too slow, rewrite later (1)\n",
    "def quick_init_and_train_word_cls_model_no_args_w2v(\n",
    "    x_train_t, x_test_t, y_train, y_test, word_model, n_dim, cls_model, weightened = False):\n",
    "    print('DATA PREPAIRING START')\n",
    "    x_train = form_corpus_matrix(x_train_t, word_model, n_dim, weightened)\n",
    "    x_test = form_corpus_matrix(x_test_t, word_model, n_dim, weightened)\n",
    "    \n",
    "    print('MODEL TRAINING START')\n",
    "    cls_m = cls_model()\n",
    "    cls_m.fit(x_train, y_train)\n",
    "    \n",
    "    y_prediction = cls_m.predict(x_test)\n",
    "    basic_report(y_test, y_prediction)\n",
    "    \n",
    "    return cls_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[35771    44]\n",
      " [ 1002   989]]\n",
      "ACCURACY:\n",
      "0.9723324340051843\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     35815\n",
      "           1       0.96      0.50      0.65      1991\n",
      "\n",
      "    accuracy                           0.97     37806\n",
      "   macro avg       0.97      0.75      0.82     37806\n",
      "weighted avg       0.97      0.97      0.97     37806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include classifier: RF\n",
    "random_forest_cls = quick_init_and_train_word_cls_model_no_args_w2v(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_w2v_vectors, n_dimensions, RandomForestClassifier, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[35632   183]\n",
      " [  618  1373]]\n",
      "ACCURACY:\n",
      "0.9788128868433582\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     35815\n",
      "           1       0.88      0.69      0.77      1991\n",
      "\n",
      "    accuracy                           0.98     37806\n",
      "   macro avg       0.93      0.84      0.88     37806\n",
      "weighted avg       0.98      0.98      0.98     37806\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# include classifier: LR\n",
    "logit_cls = quick_init_and_train_word_cls_model_no_args_w2v(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_w2v_vectors, n_dimensions, LogisticRegression\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second part of the task is: \n",
    "\n",
    "1. While performing a step 2 for text vectorization, for each word add its vector with tf-idf weight -> weighted average. \n",
    "2. Perform a same text classification task as it was required above. \n",
    "3. Calculate the metrics, compare with a vectorization approach without weightning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPAIRING START\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-ed4016ba7443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m random_forest_cls = quick_init_and_train_word_cls_model_no_args_w2v(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX_train_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_w2v_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_dimensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-132-647456253204>\u001b[0m in \u001b[0;36mquick_init_and_train_word_cls_model_no_args_w2v\u001b[1;34m(x_train_t, x_test_t, y_train, y_test, word_model, n_dim, cls_model, weightened)\u001b[0m\n\u001b[0;32m     11\u001b[0m     x_train_t, x_test_t, y_train, y_test, word_model, n_dim, cls_model, weightened = False):\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DATA PREPAIRING START'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform_corpus_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweightened\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform_corpus_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweightened\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-128-0f274041f34b>\u001b[0m in \u001b[0;36mform_corpus_matrix\u001b[1;34m(corpus, w2v_model_keyed_vectors, num_dim, weightened)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         corpus_vectorized[j] = form_text_vector(\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_model_keyed_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweightened\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mweightened\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         )\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorpus_vectorized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-128-0f274041f34b>\u001b[0m in \u001b[0;36mform_text_vector\u001b[1;34m(words_from_text, w2v_model_keyed_vectors, num_dim, weightened, corpus)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords_from_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_idf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords_from_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mweightened\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2v_model_keyed_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q * v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-128-0f274041f34b>\u001b[0m in \u001b[0;36mtf_idf\u001b[1;34m(corpus, words_from_text, word)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtf_idf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords_from_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords_from_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0midf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-128-0f274041f34b>\u001b[0m in \u001b[0;36midf\u001b[1;34m(corpus, word)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0midf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# basic formula, not sklearn modification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ineffective actually\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    312\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_platform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mmaybe_convert_platform\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random_forest_cls = quick_init_and_train_word_cls_model_no_args_w2v(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_w2v_vectors, n_dimensions, RandomForestClassifier, True\n",
    ") # (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The third part of the task is: \n",
    "\n",
    "1. Use a pre-trained W2V model for obtaining a word vectors for each of the tokens in your dataset, create text vectors WITHOUT weightning. \n",
    "2. Train text classification model.\n",
    "3. Calculate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[35794    21]\n",
      " [ 1233   758]]\n",
      "ACCURACY:\n",
      "0.9668306617997143\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     35815\n",
      "           1       0.97      0.38      0.55      1991\n",
      "\n",
      "    accuracy                           0.97     37806\n",
      "   macro avg       0.97      0.69      0.77     37806\n",
      "weighted avg       0.97      0.97      0.96     37806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include classifier: RF\n",
    "random_forest_cls = quick_init_and_train_word_cls_model_no_args_w2v(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model, n_dimensions, RandomForestClassifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fourth part of the task is: \n",
    "\n",
    "1. Use a pre-trained W2V model for obtaining a word vectors for each of the tokens in your dataset, create text vectors WITH tf-idf weightning. \n",
    "2. Train a text classification model. \n",
    "3. Calculate the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_cls = quick_init_and_train_word_cls_model_no_args_w2v(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model, n_dimensions, RandomForestClassifier, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dimentionality reduction methods such as t-SNE or PCA to make your 300 dim vectors available for 2D plotting. \n",
    "\n",
    "Select top (10-20) words for each cathegory BY TF-IDF SCORE, not counts!!! \n",
    "\n",
    "Plot on the ONE plot all of this words but colors must be different for top-words for obscene cathegory, clean, toxic, etc... \n",
    "\n",
    "See, if words from one cathegory are closer to each other than to others. \n",
    "Or you observe ~2 clusters: all of the toxic words, clean words.  \n",
    "Explain what you see and why. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as always, using PCA\n",
    "model_pca = PCA(n_components = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional part: \n",
    "\n",
    "1. Find a pre-trained FastText vectors, understand it's difference from W2V vectors. \n",
    "2. Vectorize all of your texts using FT model, perform a text classification, calculate the metrics, compare with W2V approach. \n",
    "\n",
    "Or/And you can:\n",
    "\n",
    "1. Train your own FT model and make the same. \n",
    "2. Compare it with previous approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = FastText(sentences=df_sample_cleaned_list, \n",
    "                    size=300,\n",
    "                    min_count=5,\n",
    "                    window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "number_of_iterations = 50\n",
    "\n",
    "model_ft.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model_ft.corpus_count,\n",
    "            epochs=number_of_iterations\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: \n",
    "\n",
    "Please, provide a clear table or dataframe with all of the metrics for all of the trained/used models available.   \n",
    "\n",
    "Compare them to each other.   \n",
    "\n",
    "Make conclusions which one from your models worked better for this particular task.   \n",
    "BE CAREFUL: Having a better model performance on this particular task does not matter that this model is better than others in GENERAL. You need to make your own conclusions about this particular model applied to this particular task. Please, think and understand WHY.   \n",
    "Write your thoughts down below: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your conclusions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your thoughts about the last question here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v_vectors.get_vector('daniel').shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
