{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models import FastText\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numexpr as ne\n",
    "\n",
    "ne.set_num_threads(ne.detect_number_of_cores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tokenizer, lemmatizer, stop_words, punctuation, text): \n",
    "    tokens = tokenizer(text.lower())\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return [token for token in lemmas if token not in stop_words and token not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_load = True\n",
    "\n",
    "if not bool_load:\n",
    "    df['cleaned'] = df.comment_text.apply(lambda x: preprocess_text(word_tokenize, lemmatizer, stop_words, punctuation, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_save = False\n",
    "\n",
    "if bool_save:\n",
    "    df.to_csv(\"../jigsaw-toxic-comment-classification-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133881</th>\n",
       "      <td>133881</td>\n",
       "      <td>cc37b398221b756e</td>\n",
       "      <td>\"\\n\\nAttn: Sarvagnya\\n\\nReply Hallo, , Check y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'attn', 'sarvagnya', 'reply', 'hallo', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90263</th>\n",
       "      <td>90263</td>\n",
       "      <td>f18d922aa4c9b6ed</td>\n",
       "      <td>\"Let's not start a revert war! ==\\n\\nNowhere d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'let', \"'s\", 'start', 'revert', 'war', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45385</th>\n",
       "      <td>45385</td>\n",
       "      <td>795c66905c4044fa</td>\n",
       "      <td>Tone and verification\\nThis article seems very...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['tone', 'verification', 'article', 'seems', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88078</th>\n",
       "      <td>88078</td>\n",
       "      <td>eba43d19b7ed1271</td>\n",
       "      <td>If only he was an shorty, how could call it sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['wa', 'shorty', 'could', 'call', 'shorty', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72188</th>\n",
       "      <td>72188</td>\n",
       "      <td>c143f08b0a2ad0a7</td>\n",
       "      <td>\"\\n\\n A message from the UN regarding this \"\"U...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'message', 'un', 'regarding', '``', \"''...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                id  \\\n",
       "133881      133881  cc37b398221b756e   \n",
       "90263        90263  f18d922aa4c9b6ed   \n",
       "45385        45385  795c66905c4044fa   \n",
       "88078        88078  eba43d19b7ed1271   \n",
       "72188        72188  c143f08b0a2ad0a7   \n",
       "\n",
       "                                             comment_text  toxic  \\\n",
       "133881  \"\\n\\nAttn: Sarvagnya\\n\\nReply Hallo, , Check y...      0   \n",
       "90263   \"Let's not start a revert war! ==\\n\\nNowhere d...      0   \n",
       "45385   Tone and verification\\nThis article seems very...      0   \n",
       "88078   If only he was an shorty, how could call it sh...      0   \n",
       "72188   \"\\n\\n A message from the UN regarding this \"\"U...      0   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "133881             0        0       0       0              0   \n",
       "90263              0        0       0       0              0   \n",
       "45385              0        0       0       0              0   \n",
       "88078              0        0       0       0              0   \n",
       "72188              0        0       0       0              0   \n",
       "\n",
       "                                                  cleaned  \n",
       "133881  ['``', 'attn', 'sarvagnya', 'reply', 'hallo', ...  \n",
       "90263   ['``', 'let', \"'s\", 'start', 'revert', 'war', ...  \n",
       "45385   ['tone', 'verification', 'article', 'seems', '...  \n",
       "88078   ['wa', 'shorty', 'could', 'call', 'shorty', 'c...  \n",
       "72188   ['``', 'message', 'un', 'regarding', '``', \"''...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our first model based on the vocabulary from df_sample: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With initialization model trained for 5 epochs \n",
    "\n",
    "df_sample_cleaned_list = [literal_eval(s) for s in df_sample.cleaned.tolist()]\n",
    "\n",
    "model = Word2Vec(sentences=df_sample_cleaned_list, \n",
    "         size=100,      # embedding vector size\n",
    "         min_count=5,   # consider words that occured at least 5 times\n",
    "         window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99633734, 117950070)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue training the model \n",
    "\n",
    "model.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=30\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab # to look at vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('others', 0.6437145471572876),\n",
       " ('person', 0.6037046909332275),\n",
       " ('everyone', 0.5745449066162109),\n",
       " ('thing', 0.5650192499160767),\n",
       " ('way', 0.5321717858314514),\n",
       " ('admins', 0.5284237265586853),\n",
       " ('guy', 0.5068493485450745),\n",
       " ('wikipedians', 0.5053339004516602),\n",
       " ('someone', 0.49681389331817627),\n",
       " ('editor', 0.4963911771774292)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next approach is to try to use the already pretrained model, which can be downloaded from here:\n",
    "\n",
    "https://github.com/RaRe-Technologies/gensim-data\n",
    "\n",
    "model:   \n",
    "GoogleNews-vectors-negative300.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\n",
    "    os.getcwd() + os.sep + \"GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try to use GloVe model too and experiment with it: <- later\n",
    "# import gensim.downloader as api\n",
    "# model = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Cosine similarity\n",
    "\n",
    "To measure how similar two words are, we need a way to measure the degree of similarity between two embedding vectors for the two words. Given two vectors $u$ and $v$, cosine similarity is defined as follows: \n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u . v} {||u||_2 ||v||_2} = cos(\\theta) \\tag{1}$$\n",
    "\n",
    "where $u.v$ is the dot product (or inner product) of two vectors, $||u||_2$ is the norm (or length) of the vector $u$, and $\\theta$ is the angle between $u$ and $v$. This similarity depends on the angle between $u$ and $v$. If $u$ and $v$ are very similar, their cosine similarity will be close to 1; if they are dissimilar, the cosine similarity will take a smaller value. \n",
    "\n",
    "<img src=\"cosine_sim.png\" style=\"width:800px;height:250px;\">\n",
    "<caption><center> **Figure 1**: The cosine of the angle between two vectors is a measure of how similar they are</center></caption>\n",
    "\n",
    "**Exercise**: Implement the function `cosine_similarity()` to evaluate similarity between word vectors.\n",
    "\n",
    "**Reminder**: The norm of $u$ is defined as $ ||u||_2 = \\sqrt{\\sum_{i=1}^{n} u_i^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(w1, w2):\n",
    "    \"\"\"\n",
    "    Cosine similarity between w1 and w2\n",
    "    \n",
    "    Arguments:\n",
    "        w1 : word vector        \n",
    "        w2 : word vector \n",
    "    Returns:\n",
    "        cosine_similarity \n",
    "    \"\"\"\n",
    "    if (not np.any(w1) or not np.any(w2)): # check input is not zero-vector\n",
    "        return 0\n",
    "    \n",
    "    # Dot product between w1 and w2\n",
    "    dot = np.dot(w1, w2)\n",
    "    # L2 norm of w1\n",
    "    norm_u = np.linalg.norm(w1) \n",
    "    # L2 norm of w2 \n",
    "    norm_v = np.linalg.norm(w2) \n",
    "    # Cosine similarity \n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "father = model.get_vector(\"father\")\n",
    "mother = model.get_vector(\"mother\")\n",
    "\n",
    "ball = model.get_vector(\"ball\")\n",
    "crocodile = model.get_vector(\"crocodile\")\n",
    "\n",
    "france = model.get_vector(\"france\")\n",
    "paris = model.get_vector(\"paris\")\n",
    "italy = model.get_vector(\"italy\")\n",
    "rome = model.get_vector(\"rome\")\n",
    "\n",
    "kiev = model.get_vector(\"kiev\")\n",
    "ukraine = model.get_vector(\"ukraine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.79014826\n",
      "cosine_similarity(ball, crocodile) =  0.10283584\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.1988747\n",
      "cosine_similarity(kiev, ukraine) =  0.3738725\n"
     ]
    }
   ],
   "source": [
    "fast_print = lambda u, v, tag1, tag2: print(\n",
    "    \"cosine_similarity({t1}, {t2}) = \".format(t1 = tag1, t2 = tag2), cosine_similarity(u, v)\n",
    ")\n",
    "\n",
    "fast_print(father, mother, \"father\", \"mother\")\n",
    "fast_print(ball, crocodile, \"ball\", \"crocodile\")\n",
    "fast_print(france - paris, rome - italy, \"france - paris\", \"rome - italy\")\n",
    "fast_print(kiev, ukraine, \"kiev\", \"ukraine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approximate expected output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(father, mother)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.79014826\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(ball, crocodile)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.10283585\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(france - paris, rome - italy)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         -0.421037\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Word analogy task\n",
    "\n",
    "In the word analogy task, we complete the sentence <font color='brown'>\"*a* is to *b* as *c* is to **____**\"</font>. An example is <font color='brown'> '*man* is to *woman* as *king* is to *queen*' </font>. In detail, we are trying to find a word *d*, such that the associated word vectors $e_a, e_b, e_c, e_d$ are related in the following manner: $e_b - e_a \\approx e_d - e_c$. We will measure the similarity between $e_b - e_a$ and $e_d - e_c$ using cosine similarity. \n",
    "\n",
    "**Exercise**: Complete the code below to be able to perform word analogies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note***: here you will need to complete a function in the sections, which are marked as:\n",
    "\n",
    "```\n",
    "# ----- Start ----- #\n",
    "Your code should be written in-between the lines\n",
    "# ------ End ------ #\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_analogy(word_1, word_2, word_3, model):\n",
    "    \"\"\"\n",
    "    Finds the word to complete analogy (see explanation above): a is to b as c is to ____. \n",
    "    \n",
    "    Arguments:\n",
    "    word_1 -- a word, string\n",
    "    word_2 -- a word, string\n",
    "    word_3 -- a word, string\n",
    "    model -- word embeddings model \n",
    "    \n",
    "    Returns:\n",
    "    best_word --  the word such that v_1 - v_2 is close to v_best_word - v_3, as measured by cosine similarity\n",
    "    \"\"\"\n",
    "    # convert words to lower case\n",
    "    word_1, word_2, word_3 = word_1.lower(), word_2.lower(), word_3.lower()\n",
    "    \n",
    "    # ----- Start ----- #\n",
    "    # Get the word embeddings v_a, v_b and v_c (â‰ˆ1-3 lines)\n",
    "    fast_get = lambda word: model.get_vector(word)\n",
    "    e_1, e_2, e_3 = tuple(map(fast_get, [word_1, word_2, word_3]))\n",
    "    # ------ End ------ #\n",
    "    \n",
    "    words = list(model.vocab.keys())\n",
    "    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n",
    "    best_word = None                   # Initialize best_word with None\n",
    "\n",
    "    # Loop over the whole word vector set\n",
    "    for w in words:        \n",
    "        e_j = fast_get(w)\n",
    "        # to avoid best_word being one of the input words, skip them and continue iteration.\n",
    "        if w in [word_1, word_2, word_3]:\n",
    "            continue\n",
    "        \n",
    "        # ----- Start ----- #\n",
    "        # Compute cosine similarity between the vector (e_2 - e_1) and the vector ((w's vector) - e_3)\n",
    "        cosine_sim = cosine_similarity(e_2 - e_1, e_j - e_3)\n",
    "        \n",
    "        # If the cosine_sim is more than the max_cosine_sim seen so far,\n",
    "        # do not forget to set new max_cosine_sim to the current value and best_word as well\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "        # ------ End ------ #\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man -> woman :: king -> queen\n",
      "bad -> good :: sad -> wonderful\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [\n",
    "    ('man', 'woman', 'king'), \n",
    "    ('bad', 'good', 'sad'), \n",
    "    ('man', 'woman', 'boy'), \n",
    "    ('small', 'smaller', 'large')\n",
    "]\n",
    "\n",
    "for triad in triads_to_try:\n",
    "    print('{} -> {} :: {} -> {}'.format(*triad, find_word_analogy(*triad, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **man -> woman** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         king -> queen\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **bad -> good** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         sad -> wonderful\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **man -> woman ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         boy -> girl\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **small -> smaller ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         large -> larger\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next part of the task is to:  \n",
    "\n",
    "1. Train your own W2V model using the proposed method above. Use all of the tokens created after your preprocessing pipeline in the previous tasks. (deleting stop_words, punctuation, lowercasing, etc - play as you want).  \n",
    "2. Use obtained vectors to obtain text vectors using such pipeline: \n",
    "  1. For each word in a preprocessed text, get a word vector from the W2V model. \n",
    "  2. Add them together to obtain vectors for texts (sum them together, or get mean vector) \n",
    "3. Use obtained text vectors as a text representation to perform a text classification task.  \n",
    "   Proposed - use binary classification (for example: select only 'obscene' text and clean and try to distinguish them one from another)\n",
    "4. Calculate the metrics - TP, FP, FN, TN, precision, recall, F1 score, F2 score, accurary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class callback_custom(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "         self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Iteration {:3}\".format(self.epoch+1))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   1\n",
      "Iteration   2\n",
      "Iteration   3\n",
      "Iteration   4\n",
      "Iteration   5\n"
     ]
    }
   ],
   "source": [
    "# init w2v model\n",
    "n_dimensions = 300\n",
    "\n",
    "model_w2v = Word2Vec(sentences=df_sample_cleaned_list, \n",
    "                     size=n_dimensions, min_count=5, window=5,\n",
    "                     callbacks=[callback_custom()]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   6\n",
      "Iteration   7\n",
      "Iteration   8\n",
      "Iteration   9\n",
      "Iteration  10\n",
      "Iteration  11\n",
      "Iteration  12\n",
      "Iteration  13\n",
      "Iteration  14\n",
      "Iteration  15\n",
      "...\n",
	  "Iteration  45\n",
      "Iteration  46\n",
      "Iteration  47\n",
      "Iteration  48\n",
      "Iteration  49\n",
      "Iteration  50\n",
      "Iteration  51\n",
      "Iteration  52\n",
      "Iteration  53\n",
      "Iteration  54\n",
      "Iteration  55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(166060871, 196583450)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "number_of_iterations = 50\n",
    "\n",
    "model_w2v.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model_w2v.corpus_count,\n",
    "            epochs=number_of_iterations\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('others', 0.5206615328788757),\n",
       " ('thing', 0.4942361116409302),\n",
       " ('person', 0.4668040871620178),\n",
       " (\"n't\", 0.4607079327106476),\n",
       " ('way', 0.44727379083633423),\n",
       " ('everyone', 0.4458949565887451),\n",
       " ('admins', 0.4422728419303894),\n",
       " ('editor', 0.43506354093551636),\n",
       " ('someone', 0.4273918867111206),\n",
       " ('would', 0.42714184522628784)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"n't\", 0.48523271083831787),\n",
       " ('two', 0.47902488708496094),\n",
       " ('even', 0.4700774550437927),\n",
       " ('every', 0.44541630148887634),\n",
       " ('way', 0.44086700677871704),\n",
       " ('article', 0.43976253271102905),\n",
       " (\"'s\", 0.4374009966850281),\n",
       " ('think', 0.43113958835601807),\n",
       " ('first', 0.42464885115623474),\n",
       " ('another', 0.41953933238983154)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_save_model = False\n",
    "\n",
    "if bool_save_model:\n",
    "    model_w2v.wv.save_word2vec_format('w2v_df_t2_clnd_sample.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v_vectors = model_w2v.wv # getting keyed vectors from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35290"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def is_not_outliner(\n",
    "    word: str, \n",
    "    counts: Counter,\n",
    "    counts_lim_min: int = 5,\n",
    "    length_lim_min: int = 3,\n",
    "    length_lim_max: int = 20):\n",
    "    return (counts[word] > counts_lim_min and (length_lim_min <= len(word) <= length_lim_max))\n",
    "\n",
    "\n",
    "flat_nested = lambda fl: [e for l in fl for e in l]\n",
    "fast_vocab = lambda l: set(flat_nested(l))\n",
    "\n",
    "\n",
    "mess = [literal_eval(e) for e in df['cleaned'].tolist()]\n",
    "cnts = Counter(flat_nested(mess))\n",
    "cleaned_vocab = [t for t in fast_vocab(mess) if is_not_outliner(t, cnts)]\n",
    "len(cleaned_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              texts\n",
      "0      1           ['cocksucker', 'piss', 'around', 'work']\n",
      "1      1  ['gay', 'antisemmitian', 'archangel', 'white',...\n",
      "2      1                ['fuck', 'filthy', 'mother', 'dry']\n",
      "3      1  ['stupid', 'peace', 'shit', 'stop', 'deleting'...\n",
      "4      1  ['=tony', 'sidaway', 'obviously', 'fistfuckee'...\n",
      "\n",
      "        label                                              texts\n",
      "151218      0  ['``', 'second', 'time', 'asking', 'view', 'co...\n",
      "151219      0  ['ashamed', 'horrible', 'thing', 'put', 'talk'...\n",
      "151220      0  ['spitzer', 'umm', 'actual', 'article', 'prost...\n",
      "151221      0  ['look', 'like', 'wa', 'actually', 'put', 'spe...\n",
      "151222      0  ['``', '...', 'really', \"n't\", 'think', 'under...\n"
     ]
    }
   ],
   "source": [
    "text_categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cleaned']\n",
    "\n",
    "temp = df[[text_categories[4], text_categories[-1]]]\n",
    "\n",
    "temp_n = temp[~df[text_categories[:-1]].any(axis = 'columns')]\n",
    "temp_i = temp[df.insult != 0]\n",
    "\n",
    "insulting_and_neutral = temp_i.append(temp_n).reset_index(drop = True)\n",
    "insulting_and_neutral.columns = ['label', 'texts']\n",
    "\n",
    "del temp, temp_n, temp_i\n",
    "\n",
    "print(\n",
    "    insulting_and_neutral.head(),\n",
    "    insulting_and_neutral.tail(),\n",
    "    sep = '\\n\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 0.25\n",
    "N = 75000\n",
    "\n",
    "i_and_n_sample = insulting_and_neutral.sample(N)\n",
    "\n",
    "X_train_t, X_test_t, Y_train, Y_test = train_test_split(\n",
    "    i_and_n_sample['texts'], i_and_n_sample['label'],\n",
    "    test_size = P,\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "X_train_t = [literal_eval(s) for s in X_train_t.reset_index(drop = True)]\n",
    "X_test_t = [literal_eval(s) for s in X_test_t.reset_index(drop = True)]\n",
    "\n",
    "Y_train = Y_train.reset_index(drop = True)\n",
    "Y_test = Y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_vector(tokens_list, word_model, predef_vocab, tfidf_matr = None, i = None):\n",
    "    s_t = np.zeros((1, word_model.vector_size))\n",
    "    if tfidf_matr is None:\n",
    "        for j in range(len(tokens_list)):\n",
    "            try:\n",
    "                s_t += word_model[tokens_list[j]]\n",
    "            except (KeyError, ValueError):\n",
    "                continue\n",
    "    else:\n",
    "        for j in range(len(tokens_list)):\n",
    "            try:\n",
    "                tt = tokens_list[j]\n",
    "                tq = tfidf_matr[i, predef_vocab.index(tt)]\n",
    "                s_t += word_model[tt] * tq\n",
    "            except (KeyError, ValueError):\n",
    "                continue\n",
    "    return s_t\n",
    "\n",
    "\n",
    "def get_corpus_matrix(corpus, word_model, predef_vocab, weights = False):\n",
    "    corpus_len = len(corpus)\n",
    "    sparse_matr = np.empty((corpus_len, word_model.vector_size))\n",
    "    tfidf_matr = None if not weights else TfidfVectorizer(vocabulary = predef_vocab).fit_transform(\n",
    "        [' '.join(e) for e in corpus])\n",
    "    for i in range(corpus_len):\n",
    "        sparse_matr[i] = get_token_vector(corpus[i], word_model, predef_vocab, tfidf_matr, i)\n",
    "        if not i%1000: print(i)\n",
    "    return sparse_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_report(y_test, y_prediction):\n",
    "    confusion_matr = confusion_matrix(y_test, y_prediction)\n",
    "    print(\"CONFUSION MATRIX:\\n{matr}\".format(matr=confusion_matr))\n",
    "    accuracy_of_model = accuracy_score(y_test, y_prediction)\n",
    "    print(\"ACCURACY:\\n{acc}\".format(acc = accuracy_of_model))\n",
    "    sklearn_report = classification_report(y_test, y_prediction)\n",
    "    print(\"TABLE:\\n{tab}\".format(tab=sklearn_report))\n",
    "    return (confusion_matr, accuracy_of_model, sklearn_report)\n",
    "\n",
    "\n",
    "def quick_init_and_train_word_cls_model_no_args(\n",
    "    x_train_t, x_test_t, y_train, y_test, word_model, predef_vocab, cls_model, weightened = False):\n",
    "    print('DATA PREPARATION START')\n",
    "    x_train = get_corpus_matrix(\n",
    "        x_train_t, word_model, predef_vocab, weightened\n",
    "    )\n",
    "    x_test = get_corpus_matrix(\n",
    "        x_test_t, word_model, predef_vocab, weightened\n",
    "    )\n",
    "    print('MODEL TRAINING START')\n",
    "    cls_m = cls_model()\n",
    "    cls_m.fit(x_train, y_train)\n",
    "    \n",
    "    y_prediction = cls_m.predict(x_test)\n",
    "    results = basic_report(y_test, y_prediction)\n",
    "    \n",
    "    return (cls_m, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.Word2VecKeyedVectors'>\n",
      "DATA PREPARATION START\n",
      "MODEL TRAINING START\n",
      "CONFUSION MATRIX:\n",
      "[[17734    17]\n",
      " [  602   397]]\n",
      "ACCURACY:\n",
      "0.9669866666666667\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     17751\n",
      "           1       0.96      0.40      0.56       999\n",
      "\n",
      "    accuracy                           0.97     18750\n",
      "   macro avg       0.96      0.70      0.77     18750\n",
      "weighted avg       0.97      0.97      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this time we're using rf model on our sets, because of larger amounts of it \n",
    "# include classifier: RF\n",
    "print(type(model_w2v_vectors))\n",
    "random_forest_cls_dat_1 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_w2v_vectors, cleaned_vocab, RandomForestClassifier, False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second part of the task is: \n",
    "\n",
    "1. While performing a step 2 for text vectorization, for each word add its vector with tf-idf weight -> weighted average. \n",
    "2. Perform a same text classification task as it was required above. \n",
    "3. Calculate the metrics, compare with a vectorization approach without weightning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION START\n",
      "MODEL TRAINING START\n",
      "CONFUSION MATRIX:\n",
      "[[17738    13]\n",
      " [  598   401]]\n",
      "ACCURACY:\n",
      "0.9674133333333333\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     17751\n",
      "           1       0.97      0.40      0.57       999\n",
      "\n",
      "    accuracy                           0.97     18750\n",
      "   macro avg       0.97      0.70      0.78     18750\n",
      "weighted avg       0.97      0.97      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include classifier: RF\n",
    "random_forest_cls_dat_2 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_w2v_vectors, cleaned_vocab, RandomForestClassifier, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The third part of the task is: \n",
    "\n",
    "1. Use a pre-trained W2V model for obtaining a word vectors for each of the tokens in your dataset, create text vectors WITHOUT weightning. \n",
    "2. Train text classification model.\n",
    "3. Calculate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION START\n",
      "CONFUSION MATRIX:\n",
      "[[17738    13]\n",
      " [  668   331]]\n",
      "ACCURACY:\n",
      "0.96368\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     17751\n",
      "           1       0.96      0.33      0.49       999\n",
      "\n",
      "    accuracy                           0.96     18750\n",
      "   macro avg       0.96      0.67      0.74     18750\n",
      "weighted avg       0.96      0.96      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include classifier: RF\n",
    "random_forest_cls_dat_3 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model, cleaned_vocab, RandomForestClassifier\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fourth part of the task is: \n",
    "\n",
    "1. Use a pre-trained W2V model for obtaining a word vectors for each of the tokens in your dataset, create text vectors WITH tf-idf weightning. \n",
    "2. Train a text classification model. \n",
    "3. Calculate the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION START\n",
      "MODEL TRAINING START\n",
      "CONFUSION MATRIX:\n",
      "[[17742     9]\n",
      " [  650   349]]\n",
      "ACCURACY:\n",
      "0.9648533333333333\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     17751\n",
      "           1       0.97      0.35      0.51       999\n",
      "\n",
      "    accuracy                           0.96     18750\n",
      "   macro avg       0.97      0.67      0.75     18750\n",
      "weighted avg       0.97      0.96      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include classifier: RF\n",
    "random_forest_cls_dat_4 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model, cleaned_vocab, RandomForestClassifier, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dimentionality reduction methods such as t-SNE or PCA to make your 300 dim vectors available for 2D plotting. \n",
    "\n",
    "Select top (10-20) words for each cathegory BY TF-IDF SCORE, not counts!!! \n",
    "\n",
    "Plot on the ONE plot all of this words but colors must be different for top-words for obscene cathegory, clean, toxic, etc... \n",
    "\n",
    "See, if words from one cathegory are closer to each other than to others. \n",
    "Or you observe ~2 clusters: all of the toxic words, clean words.  \n",
    "Explain what you see and why. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as always, using PCA\n",
    "model_pca = PCA(n_components = 5)\n",
    "\n",
    "transformer = TfidfVectorizer(vocabulary = cleaned_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and, as usual, a lot of mess\n",
    "text_categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'cleaned']\n",
    "\n",
    "temp = df[text_categories[-1]]\n",
    "\n",
    "fast_concat = lambda ls: [' '.join(e) for e in ls]\n",
    "g = lambda l: [literal_eval(s) for s in l]\n",
    "\n",
    "texts_neutral = fast_concat(g(temp[~df[text_categories[:-1]].any(axis = 'columns')]))\n",
    "texts_toxic = fast_concat(g(temp[df.toxic != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_concat = fast_concat(g(df.cleaned))\n",
    "tf_idf_full = transformer.fit_transform(df_cleaned_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_filter = np.zeros(len(cleaned_vocab))\n",
    "M = len(df_cleaned_concat)\n",
    "p_lim = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional part: \n",
    "\n",
    "1. Find a pre-trained FastText vectors, understand it's difference from W2V vectors. \n",
    "2. Vectorize all of your texts using FT model, perform a text classification, calculate the metrics, compare with W2V approach. \n",
    "\n",
    "Or/And you can:\n",
    "\n",
    "1. Train your own FT model and make the same. \n",
    "2. Compare it with previous approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = FastText(sentences=df_sample_cleaned_list, \n",
    "                    size=300,\n",
    "                    min_count=5,\n",
    "                    window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "number_of_iterations = 50\n",
    "\n",
    "model_ft.train(sentences=df_sample_cleaned_list, \n",
    "            total_examples=model_ft.corpus_count,\n",
    "            epochs=number_of_iterations\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION START\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "MODEL TRAINING START\n",
      "CONFUSION MATRIX:\n",
      "[[17755    38]\n",
      " [  564   393]]\n",
      "ACCURACY:\n",
      "0.9678933333333334\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     17793\n",
      "           1       0.91      0.41      0.57       957\n",
      "\n",
      "    accuracy                           0.97     18750\n",
      "   macro avg       0.94      0.70      0.77     18750\n",
      "weighted avg       0.97      0.97      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_cls_dat_5 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_ft, cleaned_vocab, RandomForestClassifier, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION START\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\laplace-transform\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "MODEL TRAINING START\n",
      "CONFUSION MATRIX:\n",
      "[[17761    32]\n",
      " [  534   423]]\n",
      "ACCURACY:\n",
      "0.9698133333333333\n",
      "TABLE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     17793\n",
      "           1       0.93      0.44      0.60       957\n",
      "\n",
      "    accuracy                           0.97     18750\n",
      "   macro avg       0.95      0.72      0.79     18750\n",
      "weighted avg       0.97      0.97      0.96     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_cls_dat_6 = quick_init_and_train_word_cls_model_no_args(\n",
    "    X_train_t, X_test_t, Y_train, Y_test, model_ft, cleaned_vocab, RandomForestClassifier, True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# saving models into c binary files, measures into dataframe\n",
    "def save_model_and_get_fancy_stats(cls_dat, cls_name):\n",
    "    dump(cls_dat[0], os.getcwd() + os.sep + cls_name + '.joblib')\n",
    "    cls_measures = list(map(float, cls_dat[1][2][70:100].split()))\n",
    "    # horrifying :D \n",
    "    return pd.Series({\n",
    "        'tp': cls_dat[1][0][0][0],\n",
    "        'tn': cls_dat[1][0][1][1],\n",
    "        'fn': cls_dat[1][0][1][0],\n",
    "        'fp': cls_dat[1][0][0][1],\n",
    "        'pre': cls_measures[0],\n",
    "        'rec': cls_measures[1],\n",
    "        'f1': cls_measures[2],\n",
    "        'acc': cls_dat[1][1]\n",
    "    }, name = cls_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(columns=['tp', 'tn', 'fp', 'fn', 'pre', 'rec', 'f1', 'acc'])\n",
    "#df_stats.set_index('model', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_stats\n",
    "df_stats = pd.read_csv(os.getcwd() + os.sep + 'models_t4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_1, 'rf_w2v_trained'))\n",
    "#df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_2, 'rf_w2v_trained_tfidf'))\n",
    "#df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_3, 'rf_w2v_pretrained'))\n",
    "#df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_4, 'rf_w2v_pretrained_tfidf'))\n",
    "#df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_5, 'rf_ft_trained'))\n",
    "#df_stats = df_stats.append(save_model_and_get_fancy_stats(random_forest_cls_dat_6, 'rf_ft_trained_tfidf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>pre</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf_ft_trained</td>\n",
       "      <td>17755.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.967893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf_ft_trained_tfidf</td>\n",
       "      <td>17761.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.969813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf_w2v_trained</td>\n",
       "      <td>17734.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.966987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf_w2v_trained_tfidf</td>\n",
       "      <td>17738.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.967413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf_w2v_pretrained</td>\n",
       "      <td>17738.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.963680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf_w2v_pretrained_tfidf</td>\n",
       "      <td>17742.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.964853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model       tp     tn    fp     fn   pre  rec    f1  \\\n",
       "0            rf_ft_trained  17755.0  393.0  38.0  564.0  0.97  1.0  0.98   \n",
       "1      rf_ft_trained_tfidf  17761.0  423.0  32.0  534.0  0.97  1.0  0.98   \n",
       "2           rf_w2v_trained  17734.0  397.0  17.0  602.0  0.97  1.0  0.98   \n",
       "3     rf_w2v_trained_tfidf  17738.0  401.0  13.0  598.0  0.97  1.0  0.98   \n",
       "4        rf_w2v_pretrained  17738.0  331.0  13.0  668.0  0.96  1.0  0.98   \n",
       "5  rf_w2v_pretrained_tfidf  17742.0  349.0   9.0  650.0  0.96  1.0  0.98   \n",
       "\n",
       "        acc  \n",
       "0  0.967893  \n",
       "1  0.969813  \n",
       "2  0.966987  \n",
       "3  0.967413  \n",
       "4  0.963680  \n",
       "5  0.964853  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(os.getcwd() + os.sep + 'models_t4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: \n",
    "\n",
    "Please, provide a clear table or dataframe with all of the metrics for all of the trained/used models available.   \n",
    "\n",
    "Compare them to each other.   \n",
    "\n",
    "Make conclusions which one from your models worked better for this particular task.   \n",
    "BE CAREFUL: Having a better model performance on this particular task does not matter that this model is better than others in GENERAL. You need to make your own conclusions about this particular model applied to this particular task. Please, think and understand WHY.   \n",
    "Write your thoughts down below: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð”Ð»Ñ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¾Ñ— Ð·Ð°Ð´Ð°Ñ‡Ñ– Ð±Ñ–Ð½Ð°Ñ€Ð½Ð¾Ñ— ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ… Ð´Ð°Ð½Ð¸Ñ… Ð²Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¾, Ñ‰Ð¾ Ð½ÐµÐ¿Ð¾Ð³Ð°Ð½Ñ– Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸ Ð¿Ð¾ÐºÐ°Ð·Ð°Ð»Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð· Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½ÑÐ¼ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñƒ Random Forest Ñ‚Ð° Ð½Ð°Ð±Ð¾Ñ€Ñƒ Ð½Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð¸Ñ… tf-idf Ð¿Ð¾ÐºÐ°Ð·Ð½Ð¸ÐºÐ°Ð¼Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¸Ñ… Ð²ÐµÐºÑ‚Ð¾Ñ€Ñ–Ð², Ñ‰Ð¾ Ð±ÑƒÐ»Ð¸ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ñ– Ð· Ð½Ð°Ñ‚Ñ€ÐµÐ½Ð¾Ð²Ð°Ð½Ð¾Ñ— Ð½Ð° Ð½Ð°ÑˆÐ¸Ñ… Ð´Ð°Ð½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»Ñ– FastText."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð”Ñ–Ð¹ÑÐ½Ð¾, Ñ…Ð¸Ð±Ð½Ð¾ Ð²Ð²Ð°Ð¶Ð°Ñ‚Ð¸ Ñ‰Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ, ÑÐºÐ° Ð¿Ñ€Ð¾ÑÐ²Ð¸Ð»Ð° ÑÐµÐ±Ðµ Ð´Ð¾Ð±Ñ€Ðµ Ð½Ð° Ð¾Ð´Ð½Ñ–Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ñ–, Ð±ÑƒÐ´Ðµ Ð´Ð°Ð²Ð°Ñ‚Ð¸ Ð´Ð¾Ð±Ñ€Ñ– Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸ Ð´Ð»Ñ Ñ–Ð½ÑˆÐ¸Ñ….\n",
    "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ñ– Ð¼Ð¾Ð´ÐµÐ»Ñ– Ñƒ Ñ†ÑŒÐ¾Ð¼Ñƒ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ– Ð¿Ñ€Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ñ– Ð´Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ Ñ‚ÐµÐºÑÑ‚Ñ–Ð².\n",
    "ÐšÑ–Ð»ÑŒÐºÐ° ÑÐ»Ñ–Ð² Ð¿Ñ€Ð¾ Ð¾Ð±Ñ€Ð°Ð½Ñƒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð² ÑÐºÐ¾ÑÑ‚Ñ– Ð½Ð°Ð¹ÐºÑ€Ð°Ñ‰Ð¾Ñ— Ð´Ð»Ñ Ð·Ð°Ð´Ð°Ñ‡Ñ– Ð±Ñ–Ð½Ð°Ñ€Ð½Ð¾Ñ— ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—. ÐžÑÐ½Ð¾Ð²Ð½Ð¸Ð¼Ð¸ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð°Ð¼Ð¸, Ñ‰Ð¾ ÑÐ¿Ñ€Ð¸ÑÐ»Ð¸ Ñ†ÑŒÐ¾Ð¼Ñƒ, Ñ” Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ñ–: Ð½Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ… ÑÐ»Ñ–Ð² Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½ÑÐ¼Ð¸ tf-idf (Ð¿Ð¾ÐºÐ°Ð·Ð½Ð¸Ðº Ð·Ð½Ð°Ñ‡ÑƒÑ‰Ð¾ÑÑ‚Ñ– ÑÐ»Ð¾Ð²Ð° Ð´Ð°Ñ” Ð·Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾ÐºÑ€Ð°Ñ‰Ð¸Ñ‚Ð¸ Ñ€Ð¾Ð±Ð¾Ñ‚Ñƒ Ð² Ñ†Ñ–Ð»Ð¾Ð¼Ñƒ),\n",
    "Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ FastText/Word2Vec Ñ‚Ð° Ð´Ð°Ð½Ñ–, ÑÐºÑ– Ð±ÑƒÐ»Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ñ– Ð´Ð»Ñ Ñ‚Ñ€ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ñ‚Ð° Ñ„Ð¾Ñ€Ð¼ÑƒÐ²Ð°Ð½Ð½Ñ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¸Ñ… Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½ÑŒ ÑÐ»Ñ–Ð²."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
